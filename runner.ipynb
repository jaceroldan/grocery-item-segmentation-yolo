{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# no nvlink\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "# use a specific GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['images', 'categories', 'annotations'])\n",
      "[{'id': 16, 'name': 'pineapple juice', 'supercategory': '', 'color': '#d6504a', 'metadata': {}, 'keypoint_colors': []}, {'supercategory': 'category_id', 'id': 18, 'name': '18'}, {'supercategory': 'type', 'id': 24, 'name': 'GreenCross Ethyl Alcohol'}, {'id': 19, 'name': 'pink_shampoo', 'supercategory': '', 'color': '#35e071', 'metadata': {}, 'keypoint_colors': []}, {'supercategory': 'type', 'id': 22, 'name': 'toothpaste'}, {'id': 8, 'name': 'garlic', 'supercategory': '', 'color': '#b059f0', 'metadata': {}, 'keypoint_colors': []}, {'id': 14, 'name': 'peanut_butter', 'supercategory': '', 'color': '#dccd1c', 'metadata': {}, 'keypoint_colors': []}, {'id': 6, 'name': 'Cooking_oil', 'supercategory': '', 'color': '#10d39c', 'metadata': {}, 'creator': 'jeryl4913', 'keypoint_colors': []}, {'id': 20, 'name': '20', 'supercategory': '', 'color': '#613fe3', 'metadata': {}, 'keypoint_colors': []}, {'supercategory': 'type', 'id': 1, 'name': 'bottled_soda'}, {'id': 13, 'name': 'Mayonnaise', 'supercategory': '', 'color': '#9c25ef', 'metadata': {}, 'keypoint_colors': []}, {'id': 21, 'name': 'silverswan', 'supercategory': '', 'color': '#0b26b3', 'metadata': {}, 'keypoint_colors': []}, {'id': 23, 'name': 'canned-tuna', 'supercategory': '', 'color': '#cf3750', 'metadata': {}, 'creator': 'gagluba', 'keypoint_colors': []}, {'id': 2, 'name': 'cheese', 'supercategory': '', 'color': '#74e7e6', 'metadata': {}, 'keypoint_colors': []}, {'id': 9, 'name': 'instant_noodles', 'supercategory': '', 'color': '#fec700', 'metadata': {}, 'keypoint_colors': []}, {'supercategory': 'type', 'id': 15, 'name': 'pasta'}, {'id': 17, 'name': 'crackers', 'supercategory': '', 'color': '#576aff', 'metadata': {}, 'keypoint_colors': []}, {'id': 11, 'datatorch_id': '29f4bb67-39a4-4dae-9414-851025f39266', 'name': 'lemon', 'supercategory': None}, {'id': 3, 'name': 'Kitkat', 'supercategory': '', 'color': '#ff2600', 'metadata': {}, 'keypoint_colors': []}, {'id': 5, 'name': 'condensed_milk', 'supercategory': '', 'color': '#dd3d9f', 'metadata': {}, 'keypoint_colors': []}, {'id': 4, 'name': 'coffee', 'supercategory': '', 'color': '#2445e2', 'metadata': {}, 'keypoint_colors': []}, {'id': 7, 'name': 'corned beef'}]\n",
      "[{'id': 1, 'name': 'bottled_soda'}, {'id': 2, 'name': 'cheese'}, {'id': 3, 'name': 'Kitkat'}, {'id': 4, 'name': 'coffee'}, {'id': 5, 'name': 'condensed_milk'}, {'id': 6, 'name': 'Cooking_oil'}, {'id': 7, 'name': 'corned beef'}, {'id': 8, 'name': 'garlic'}, {'id': 9, 'name': 'instant_noodles'}, {'id': 11, 'name': 'lemon'}, {'id': 13, 'name': 'Mayonnaise'}, {'id': 14, 'name': 'peanut_butter'}, {'id': 15, 'name': 'pasta'}, {'id': 16, 'name': 'pineapple juice'}, {'id': 17, 'name': 'crackers'}, {'id': 18, 'name': '18'}, {'id': 19, 'name': 'pink_shampoo'}, {'id': 20, 'name': '20'}, {'id': 21, 'name': 'silverswan'}, {'id': 22, 'name': 'toothpaste'}, {'id': 23, 'name': 'canned-tuna'}, {'id': 24, 'name': 'GreenCross Ethyl Alcohol'}]\n",
      "22\n",
      "['bottled_soda', 'cheese', 'Kitkat', 'coffee', 'condensed_milk', 'Cooking_oil', 'corned beef', 'garlic', 'instant_noodles', 'lemon', 'Mayonnaise', 'peanut_butter', 'pasta', 'pineapple juice', 'crackers', '18', 'pink_shampoo', '20', 'silverswan', 'toothpaste', 'canned-tuna', 'GreenCross Ethyl Alcohol']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/data/students/juan/train/grocery-item-segmentation-yolo/dataset/annotations/instances_train.json') as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "print(annotations.keys())\n",
    "print(annotations['categories'])\n",
    "category_names = sorted([{'id': ac['id'], 'name': ac['name']} for ac in annotations['categories']], key=lambda x: x['id'])\n",
    "print(category_names)\n",
    "print(len(category_names))\n",
    "print([ac['name'] for ac in category_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current running training script with YOLO8-nano.\n",
    "\n",
    "`yolo task=segment mode=train model=yolov8n-seg.pt data=config.yaml epochs=1 imgsz=640`\n",
    "\n",
    "Current running validation script with YOLO8-nano.\n",
    "\n",
    "`yolo task=segment mode=val model=yolov8n-seg.pt data=config.yaml epochs=1 imgsz=640`\n",
    "\n",
    "Current running inference script with YOLO8-nano.\n",
    "\n",
    "`yolo task=segment mode=predict model=yolov8n-seg.pt source=/data/detection/grocery/dataset/images/val`\n",
    "\n",
    "References:\n",
    "\n",
    "* https://docs.ultralytics.com/datasets/segment/#port-or-convert-label-formats\n",
    "* https://github.com/ultralytics/JSON2YOLO/blob/main/general_json2yolo.py\n",
    "* https://stackoverflow.com/questions/76651217/how-to-use-one-json-label-file-for-all-the-training-images-for-yolo-nas \n",
    "* https://github.com/ultralytics/ultralytics/issues/11268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.29 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40339MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=config.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train4\n",
      "Overriding model.yaml nc=80 with nc=22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1008370  ultralytics.nn.modules.head.Segment          [22, 32, 64, [64, 128, 256]]  \n",
      "YOLOv8n-seg summary: 261 layers, 3,267,906 parameters, 3,267,890 gradients, 12.1 GFLOPs\n",
      "\n",
      "Transferred 381/417 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /raid/students/juan/train/grocery-item-segmentation-yolo/dataset\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/030178.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.06562]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/040246.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.038126  1.1077061]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070019.jpg: ignoring corrupt image/label: negative label values [-0.0085792]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070021.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.000813]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070022.jpg: ignoring corrupt image/label: negative label values [-0.0170135  -0.01406075]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070023.jpg: ignoring corrupt image/label: negative label values [-0.0073116]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070024.jpg: ignoring corrupt image/label: negative label values [-0.0087881]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070031.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.010055]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070045.jpg: ignoring corrupt image/label: negative label values [-0.0003515]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070046.jpg: ignoring corrupt image/label: negative label values [-0.0060235]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070047.jpg: ignoring corrupt image/label: negative label values [-0.0068815]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070061.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.014827]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070063.jpg: ignoring corrupt image/label: negative label values [-0.01663795]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070068.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.008364]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070072.jpg: ignoring corrupt image/label: negative label values [-0.0150099]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070073.jpg: ignoring corrupt image/label: negative label values [-0.013017]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070085.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0085809]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070087.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.012863]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/070229.jpg: ignoring corrupt image/label: negative label values [-0.07045849]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/110011.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.015311]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/110154.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0101955 1.0250405]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/110155.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0430745 1.001148 ]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/110335.jpg: ignoring corrupt image/label: negative label values [-0.0277344]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/130346.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0027117]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150033.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0833349]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150044.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0270815]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150239.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.017185]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150241.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.149997]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150260.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0062532]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150274.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.177083]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150276.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0484375]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/150278.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0374975]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/160205.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0016633]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/160278.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0043747]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/180110.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [3.9421902 2.7864552 1.5562499]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/190118.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0011483 1.0040587]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/210157.jpg: ignoring corrupt image/label: negative label values [-0.00166665]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/210213.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0067711]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/210214.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0346866]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/210218.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.015065]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/train/230097.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0004166]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/l\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/070049.jpg: ignoring corrupt image/label: negative label values [-0.0024665]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/070056.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.001284]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/070059.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0047395]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/070064.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0024115]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/070070.jpg: ignoring corrupt image/label: negative label values [-0.0107671]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/090039.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.0035976]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/150035.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.1479164]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/images/val/160190.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [1.000625]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /raid/students/juan/train/grocery-item-segmentation-yolo/dataset/labels/val.cache\n",
      "Plotting labels to runs/segment/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/segment/train4\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      3.08G     0.8216      2.489      3.257      1.111         15   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        767       1693      0.611      0.617      0.631      0.526      0.591      0.601      0.602      0.493\n",
      "\n",
      "1 epochs completed in 0.043 hours.\n",
      "Optimizer stripped from runs/segment/train4/weights/last.pt, 6.8MB\n",
      "Optimizer stripped from runs/segment/train4/weights/best.pt, 6.8MB\n",
      "\n",
      "Validating runs/segment/train4/weights/best.pt...\n",
      "Ultralytics 8.3.29 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40339MiB)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3,262,354 parameters, 0 gradients, 12.0 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        767       1693      0.612      0.617      0.631      0.526      0.592      0.601      0.602      0.493\n",
      "          bottled_soda         37         37      0.652      0.378      0.421      0.332      0.642      0.378      0.421      0.339\n",
      "                cheese         40         58      0.368      0.345       0.31      0.192       0.33       0.31      0.286      0.215\n",
      "                Kitkat         42         47          1      0.271      0.626      0.533          1      0.272      0.623      0.499\n",
      "                coffee         30         66      0.606      0.621      0.672      0.525      0.591      0.606      0.654      0.511\n",
      "        condensed_milk         37         52      0.459      0.712      0.709      0.667      0.459      0.712        0.7      0.645\n",
      "           Cooking_oil         40         40      0.705      0.725      0.798      0.669      0.703      0.725      0.798      0.704\n",
      "           corned beef         36        179      0.667      0.911      0.875      0.684      0.634      0.866      0.815      0.542\n",
      "                garlic         33         33      0.691      0.758      0.779      0.628      0.691      0.758      0.779      0.618\n",
      "       instant_noodles         29         29      0.912          1      0.989      0.886      0.912          1      0.989      0.951\n",
      "                 lemon         37         46      0.939          1      0.982      0.949      0.939          1      0.982        0.9\n",
      "            Mayonnaise         31        105      0.406      0.659      0.594      0.443      0.356      0.581      0.439      0.217\n",
      "         peanut_butter         26        158      0.312      0.469      0.406      0.322      0.257      0.386      0.316      0.225\n",
      "                 pasta         36         38      0.251      0.289      0.177      0.144      0.249      0.289      0.169      0.141\n",
      "       pineapple juice         34        115      0.716      0.704      0.794      0.725      0.716      0.704      0.794        0.7\n",
      "              crackers         32         48      0.396      0.888      0.751      0.573      0.406      0.911      0.759      0.624\n",
      "                    18         45         61      0.341       0.18      0.212      0.184       0.34       0.18      0.212      0.175\n",
      "          pink_shampoo         36         51      0.758      0.922      0.904      0.792      0.758      0.922      0.904      0.828\n",
      "                    20         34         34      0.931      0.799      0.925      0.875      0.931      0.799      0.925      0.867\n",
      "            silverswan         34         95       0.54      0.347      0.332      0.206      0.503      0.326      0.295      0.162\n",
      "            toothpaste         25         42      0.876      0.762      0.907      0.776      0.848      0.738      0.883      0.734\n",
      "           canned-tuna         42        326      0.671      0.411      0.458      0.344      0.485      0.298      0.223      0.108\n",
      "GreenCross Ethyl Alcohol         31         33      0.262      0.424      0.263      0.126       0.28      0.455      0.276      0.143\n",
      "Speed: 0.3ms preprocess, 0.8ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/segment/train4\u001b[0m\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "!yolo task=segment mode=train model=yolov8n-seg.pt data=config.yaml epochs=1 imgsz=640"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
